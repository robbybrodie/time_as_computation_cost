{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robbybrodie/time_as_computation_cost/blob/main/notebooks/02_Tension_Bandgaps_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Tension Bandgaps Experiment\n",
        "\n",
        "This notebook explores micro fitting and model selection with synthetic data.\n",
        "\n",
        "## Theory\n",
        "\n",
        "- **DoF Law**: DoF(N) = exp(-a*(1-N)) + noise\n",
        "- **Mapping**: ψ = DoF^β\n",
        "- **Model Comparison**: Exponential vs Polynomial vs Power Law\n",
        "- **Selection Criteria**: AIC, BIC, Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bootstrap"
      },
      "outputs": [],
      "source": [
        "# Colab bootstrap\n",
        "REPO_URL = \"https://github.com/robbybrodie/time_as_computation_cost.git\"\n",
        "REPO_NAME = \"time_as_computation_cost\"\n",
        "\n",
        "import pathlib\n",
        "if not pathlib.Path(REPO_NAME).exists():\n",
        "    !git clone $REPO_URL\n",
        "%cd $REPO_NAME\n",
        "\n",
        "if pathlib.Path(\"pyproject.toml\").exists():\n",
        "    !pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "from experiments.run_tension_bandgaps import main\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Ensure we can import the modules\n",
        "repo_root = Path().resolve()\n",
        "sys.path.insert(0, str(repo_root / \"src\"))\n",
        "\n",
        "from tacc.bandgaps.tension import run_demo, run_experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basic_experiment"
      },
      "source": [
        "## Basic Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_basic"
      },
      "outputs": [],
      "source": [
        "# Run the basic experiment\n",
        "results = main()\n",
        "\n",
        "print(\"Model fitting completed!\")\n",
        "print(f\"a_hat: {results['fitted_params']['a_hat']:.3f} (true: 2.0)\")\n",
        "print(f\"beta_hat: {results['fitted_params']['beta_hat']:.3f} (true: 1.5)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive_demo"
      },
      "source": [
        "## Interactive Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demo_plot"
      },
      "outputs": [],
      "source": [
        "# Create and display demo visualization\n",
        "fig = run_demo(n_points=50, noise_sigma=0.05, a_true=2.0, beta_true=1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noise_exploration"
      },
      "source": [
        "## Noise Level Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_noise"
      },
      "outputs": [],
      "source": [
        "# Explore different noise levels\n",
        "noise_levels = [0.01, 0.05, 0.1, 0.2]\n",
        "a_true, beta_true = 2.0, 1.5\n",
        "\n",
        "results_by_noise = []\n",
        "for noise in noise_levels:\n",
        "    exp_result = run_experiment(noise_sigma=noise, a_true=a_true, beta_true=beta_true)\n",
        "    results_by_noise.append(exp_result)\n",
        "\n",
        "# Plot parameter recovery\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "a_hats = [r['fitted_params']['a_hat'] for r in results_by_noise]\n",
        "beta_hats = [r['fitted_params']['beta_hat'] for r in results_by_noise]\n",
        "\n",
        "ax1.plot(noise_levels, a_hats, 'bo-', linewidth=2, markersize=8, label='Fitted a')\n",
        "ax1.axhline(y=a_true, color='r', linestyle='--', label=f'True a = {a_true}')\n",
        "ax1.set_xlabel('Noise Level σ')\n",
        "ax1.set_ylabel('Parameter a')\n",
        "ax1.set_title('Parameter Recovery: a')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.plot(noise_levels, beta_hats, 'go-', linewidth=2, markersize=8, label='Fitted β')\n",
        "ax2.axhline(y=beta_true, color='r', linestyle='--', label=f'True β = {beta_true}')\n",
        "ax2.set_xlabel('Noise Level σ')\n",
        "ax2.set_ylabel('Parameter β')\n",
        "ax2.set_title('Parameter Recovery: β')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Parameter Recovery Summary:\")\n",
        "for i, noise in enumerate(noise_levels):\n",
        "    print(f\"σ={noise}: a_hat={a_hats[i]:.3f}, β_hat={beta_hats[i]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_comparison"
      },
      "source": [
        "## Model Comparison Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compare_models"
      },
      "outputs": [],
      "source": [
        "# Detailed model comparison\n",
        "noise_sigma = 0.05\n",
        "detailed_results = run_experiment(noise_sigma=noise_sigma)\n",
        "\n",
        "# Extract model comparison data\n",
        "models = ['exponential', 'polynomial', 'power_law']\n",
        "model_names = ['Exponential', 'Polynomial-2', 'Power Law']\n",
        "\n",
        "aic_scores = [detailed_results['model_comparison'][model]['aic'] for model in models]\n",
        "bic_scores = [detailed_results['model_comparison'][model]['bic'] for model in models]\n",
        "cv_scores = [detailed_results['model_comparison'][model]['cv_score'] for model in models]\n",
        "cv_stds = [detailed_results['model_comparison'][model]['cv_std'] for model in models]\n",
        "\n",
        "# Create comparison plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# AIC/BIC comparison\n",
        "x_pos = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x_pos - width/2, aic_scores, width, label='AIC', alpha=0.8)\n",
        "ax1.bar(x_pos + width/2, bic_scores, width, label='BIC', alpha=0.8)\n",
        "ax1.set_xlabel('Model')\n",
        "ax1.set_ylabel('Score (lower is better)')\n",
        "ax1.set_title('Information Criteria')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(model_names, rotation=45)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Cross-validation comparison\n",
        "ax2.bar(x_pos, cv_scores, yerr=cv_stds, capsize=5, alpha=0.8)\n",
        "ax2.set_xlabel('Model')\n",
        "ax2.set_ylabel('CV MSE (lower is better)')\n",
        "ax2.set_title('Cross-Validation Performance')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(model_names, rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find best model\n",
        "best_aic_idx = np.argmin(aic_scores)\n",
        "best_cv_idx = np.argmin(cv_scores)\n",
        "\n",
        "print(f\"\\nModel Comparison Results (σ = {noise_sigma}):\")\n",
        "print(\"=\" * 40)\n",
        "for i, (model, name) in enumerate(zip(models, model_names)):\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  AIC: {aic_scores[i]:.2f}\")\n",
        "    print(f\"  BIC: {bic_scores[i]:.2f}\")\n",
        "    print(f\"  CV MSE: {cv_scores[i]:.4f} ± {cv_stds[i]:.4f}\")\n",
        "    print()\n",
        "\n",
        "print(f\"Best model (AIC): {model_names[best_aic_idx]}\")\n",
        "print(f\"Best model (CV): {model_names[best_cv_idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusions"
      },
      "source": [
        "## Key Insights\n",
        "\n",
        "1. **Parameter Recovery**: Exponential model successfully recovers true parameters\n",
        "2. **Noise Robustness**: Performance degrades gracefully with increasing noise\n",
        "3. **Model Selection**: AIC/BIC correctly identify exponential as best model\n",
        "4. **Cross-validation**: Confirms model ranking from information criteria\n",
        "\n",
        "## Physical Interpretation\n",
        "\n",
        "- **DoF(N)**: \"Degrees of freedom\" as function of computational capacity\n",
        "- **Exponential Law**: Suggests exponential suppression as capacity decreases\n",
        "- **β Parameter**: Controls nonlinear mapping to observable quantity ψ\n",
        "\n",
        "**Note**: This uses synthetic data - real physics validation needed!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
